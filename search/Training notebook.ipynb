{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports and globals\n",
    "import numpy as np\n",
    "from cnns.core import LasagneGoogLeNetInceptionV3 as inceptv3\n",
    "from cnns.utils import cnn_utils as cu\n",
    "from cnns.utils import process_utils as pu\n",
    "from cnns.utils import training_utils as tu\n",
    "from ds_utils import data_utils as du\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "cnn_dir = '/Users/babasarala/repos/cnns'\n",
    "model_dir = '%s/models'%cnn_dir\n",
    "output_dir = '/Users/babasarala/Desktop'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data from tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# define the categories:\n",
    "categories = {'food':0.5, 'documents':1., 'whiteboards':1., 'sketches':1., 'other':0.05} \n",
    "\n",
    "# define the model we want to use for generating CNN codes\n",
    "param_pkl_filepath = '/Users/babasarala/repos/cnns/models/inception_v3.pkl'\n",
    "model = inceptv3.LasagneGoogLeNetInceptionV3(param_pkl_filepath)\n",
    "layer = 'pool3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the data\n",
    "dfs = []\n",
    "cur = tu.start_psycon()\n",
    "for category in categories:\n",
    "    everalbum_sample_urls = tu.get_sample_image_urls_from_everalbum_for_category(cur, category=category, \n",
    "                                                                                 p=categories[category])\n",
    "    imagenet_sample_urls = tu.get_sample_image_urls_from_imagenet_for_category(cur, category=category, \n",
    "                                                                               p=categories[category])\n",
    "    curr_df = pd.DataFrame(everalbum_sample_urls + imagenet_sample_urls, columns=['img_url'])\n",
    "    curr_df['category'] = category\n",
    "    dfs.append(curr_df)\n",
    "\n",
    "df_img_urls = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_img_urls.to_csv('/Users/babasarala/Desktop/training_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_complete_data_from_intermediate_results(results_dirpath, csv_filepath=None):\n",
    "    img_urls, X = pu.combine_checkpoint_intermediate_results(results_dirpath)\n",
    "    if csv_filepath is not None:\n",
    "        img_url_cats = pd.read_csv(csv_filepath)\n",
    "        assert 'img_url' in img_url_cats.columns\n",
    "        assert 'category' in img_url_cats.columns\n",
    "    \n",
    "    m, d = X.shape\n",
    "    feat_cols = ['f%i'%i for i in range(d)]\n",
    "    data_matrix = pd.DataFrame(data=X, columns=feat_cols)\n",
    "    data_matrix['img_url'] = img_urls\n",
    "    complete_data = pd.merge(data_matrix, img_url_cats)\n",
    "    \n",
    "    return complete_data, feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_dirpath = '/Users/babasarala/Desktop/evaluation/dataset/productivity_food_dataset_v1.1'\n",
    "results_dirpath = '%s/GoogLeNetv3_pool3_fvs'%(dataset_dirpath)\n",
    "csv_filepath = '%s/productivity_food_dataset_v1.1.csv'%(dataset_dirpath)\n",
    "complete_data, feat_cols = construct_complete_data_from_intermediate_results(results_dirpath, csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other          53265\n",
      "food           14338\n",
      "documents       1373\n",
      "whiteboards      168\n",
      "sketches          69\n",
      "dtype: int64\n",
      "['food' 'sketches' 'documents' 'whiteboards' 'other']\n"
     ]
    }
   ],
   "source": [
    "print complete_data['category'].value_counts()\n",
    "categories = complete_data['category'].unique()\n",
    "print categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set seeds\n",
    "train_random_seed = np.random.randint(low=0, high=99999)\n",
    "prod_random_seed = np.random.randint(low=0, high=99999)\n",
    "\n",
    "# create mappings\n",
    "mappings = {}\n",
    "for idx, category in enumerate(categories):\n",
    "    mappings[category] = idx\n",
    "    mappings[idx] = category\n",
    "\n",
    "# tag training and testing labels\n",
    "p = 0.6\n",
    "m = complete_data.shape[0]\n",
    "train_test_cats = tu.assign_train_test(m, p=p)\n",
    "complete_data['set'] = train_test_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          penalty='l1', random_state=59827, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on this data\n",
    "train_lr = linear_model.LogisticRegression(penalty='l1', multi_class='multinomial', solver='lbfgs', \n",
    "                                           random_state=train_random_seed)\n",
    "pipe = Pipeline(steps=[\n",
    "        ('normalizer', StandardScaler()),\n",
    "        ('classifier', train_lr)\n",
    "        ])\n",
    "params = dict(classifier__C=[1e-4, 1e-3, 1e-2, 0.1, 1, 10, 1e2, 1e3, 1e4])\n",
    "train_clf = GridSearchCV(pipe, param_grid=params, cv=5)\n",
    "\n",
    "# full data, in matrix form\n",
    "X = complete_data[feat_cols].values\n",
    "y = [mappings[category] for category in complete_data['category'].values]\n",
    "\n",
    "# train-test split\n",
    "training_data =  complete_data[complete_data['set'] == 'train']\n",
    "testing_data = complete_data[complete_data['set'] == 'test']\n",
    "X_tr = training_data[feat_cols].values\n",
    "y_tr = [mappings[category] for category in training_data['category'].values]\n",
    "X_te = testing_data[feat_cols].values\n",
    "y_te = [mappings[category] for category in testing_data['category'].values]\n",
    "\n",
    "best_clf = train_clf.fit(X_tr,y_tr)\n",
    "y_pred = best_clf.predict(X_te)\n",
    "clf_report = classification_report(y_te, y_pred)\n",
    "conf_mat = confusion_matrix(y_te,y_pred)\n",
    "\n",
    "# final classifier\n",
    "best_C = train_clf.best_params_['classifier__C']\n",
    "prod_lr = linear_model.LogisticRegression(C=best_C, penalty='l1', multi_class='multinomial', solver='lbfgs', \n",
    "                                           random_state=prod_random_seed)\n",
    "prod_clf = Pipeline(steps=[\n",
    "            ('normalizer', StandardScaler()),\n",
    "            ('classifier', prod_lr)\n",
    "            ])\n",
    "prod_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.85      0.90      5663\n",
      "          1       0.92      0.50      0.65        24\n",
      "          2       0.82      0.64      0.72       547\n",
      "          3       0.97      0.84      0.90        73\n",
      "          4       0.95      0.99      0.97     21379\n",
      "\n",
      "avg / total       0.95      0.95      0.95     27686\n",
      "\n",
      "[[ 4821     0     0     0   842]\n",
      " [    0    12     5     0     7]\n",
      " [    2     0   349     2   194]\n",
      " [    0     0     7    61     5]\n",
      " [  247     1    64     0 21067]]\n"
     ]
    }
   ],
   "source": [
    "print clf_report\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.86      0.91      5780\n",
      "          1       0.64      0.32      0.43        28\n",
      "          2       0.82      0.65      0.73       524\n",
      "          3       0.98      0.68      0.80        65\n",
      "          4       0.95      0.99      0.97     21289\n",
      "\n",
      "avg / total       0.95      0.95      0.95     27686\n",
      "\n",
      "[[ 4964     0     0     0   816]\n",
      " [    0     9     7     0    12]\n",
      " [    0     1   339     1   183]\n",
      " [    0     4     7    44    10]\n",
      " [  216     0    58     0 21015]]\n"
     ]
    }
   ],
   "source": [
    "print \n",
    "print clf_report\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()\n",
    "formatted_time = du.format_tstamp(dt, frmt='%Y-%m-%d %H_%M_%S')\n",
    "posix_time = du.datetime_to_posix(dt)\n",
    "description_str = 'L1-regularized Logistic Regression on CNN codes of Food (No drink) / Documents / \\\n",
    "                   Sketches / Whiteboards after applying Inception v3 as a filter_v2.'\n",
    "\n",
    "data_and_model = { # metadata \n",
    "                  'unique_id': posix_time,\n",
    "                  'date_created': formatted_time,\n",
    "                  'mappings': mappings,\n",
    "                  'model_lib':model.model_lib,\n",
    "                  'model_name':model.model_name,\n",
    "                  'layer': layer,\n",
    "    \n",
    "                  # complete data\n",
    "                  'complete_data': complete_data,\n",
    "                  \n",
    "                  # training and performance eval\n",
    "                  'perc_tr': p,\n",
    "                  'training_seed': train_random_seed,\n",
    "                  'training_model':train_clf,\n",
    "                  'description': description_str,\n",
    "                  'confusion_matrix': conf_mat,\n",
    "                  'classification_report': clf_report,\n",
    "                  \n",
    "                  # production classifier\n",
    "                  'production_seed': prod_random_seed,\n",
    "                  'prod_model': prod_clf\n",
    "                  }\n",
    "\n",
    "model_only = {'unique_id':posix_time, \n",
    "              'mappings':mappings, \n",
    "              'date_created': formatted_time, \n",
    "              'prod_model': prod_clf}\n",
    "\n",
    "data_and_model_filename_str = '%s_L1_LR.p'%(formatted_time)\n",
    "data_and_model_savepath = '%s/%s'%(model_dir, data_and_model_filename_str)\n",
    "model_only_filename_str = '%s_model_only_L1_LR.p'%(formatted_time)\n",
    "model_only_savepath = '%s/%s'%(model_dir, model_only_filename_str)\n",
    "\n",
    "if os.path.isfile(data_and_model_savepath):\n",
    "    print 'This file already exists!!'\n",
    "else:\n",
    "    pkl.dump(data_and_model, open(data_and_model_savepath, 'wb'))\n",
    "\n",
    "if os.path.isfile(model_only_savepath):\n",
    "    print 'This file already exists!!'\n",
    "else:\n",
    "    pkl.dump(model_only, open(model_only_savepath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load previous classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dirpath = '/Users/babasarala/repos/cnns/models/2016-07-27 12_58_53_L1_LR.p'\n",
    "d = pkl.load(open(model_dirpath, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
