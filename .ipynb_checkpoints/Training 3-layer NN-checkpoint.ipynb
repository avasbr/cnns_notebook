{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and globals\n",
    "import numpy as np\n",
    "from cnns.core import LasagneGoogLeNetInceptionV3 as inceptv3\n",
    "from cnns.utils import cnn_utils as cu\n",
    "from cnns.utils import process_utils as pu\n",
    "from cnns.utils import training_utils as tu\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.updates import nesterov_momentum, adam\n",
    "from lasagne.layers import get_all_params\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n",
    "from nolearn.lasagne import objective\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "cnn_dir = '/Users/babasarala/repos/cnns'\n",
    "eval_dirpath = '/Users/babasarala/Desktop/evaluation'\n",
    "model_dir = '%s/models'%cnn_dir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_dirpath = '%s/dataset/productivity_food_dataset_v1.2'%(eval_dirpath)\n",
    "csv_filepath = '%s/productivity_food_dataset_v1.2.csv'%(dataset_dirpath)\n",
    "results_dirpath = '%s/GoogLeNetv3_pool3_fvs'%(dataset_dirpath)\n",
    "complete_data, feat_cols = construct_complete_data_from_intermediate_results(results_dirpath, csv_filepath)\n",
    "\n",
    "# set seeds\n",
    "train_random_seed = np.random.randint(low=0, high=99999)\n",
    "prod_random_seed = np.random.randint(low=0, high=99999)\n",
    "\n",
    "# create mappings\n",
    "categories = ['food', 'documents', 'whiteboards', 'sketches', 'other']\n",
    "mappings = {}\n",
    "for idx, category in enumerate(categories):\n",
    "    mappings[category] = idx\n",
    "    mappings[idx] = category\n",
    "\n",
    "# tag training and testing labels\n",
    "m = complete_data.shape[0]\n",
    "X = complete_data[feat_cols].values.astype(np.float32)\n",
    "y = np.array([mappings[category] for category in complete_data['category'].values]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_size = 2048\n",
    "num_hidden_units = 200\n",
    "output_size = 5\n",
    "update_learning_rate = 0.01\n",
    "update_momentum=0.9\n",
    "max_epochs=500\n",
    "optimizer=nesterov_momentum\n",
    "split_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet = NeuralNet(\n",
    "        layers=[\n",
    "            # Input layer\n",
    "            (InputLayer, {'shape': (None, input_size)}),\n",
    "            (DropoutLayer, {'p':0.2}),\n",
    "            # Hidden layer\n",
    "            (DenseLayer, {'num_units': num_hidden_units,\n",
    "                          'nonlinearity': rectify}),\n",
    "            (DropoutLayer, {'p':0.5}),    \n",
    "            # Output (Softmax) layer\n",
    "            (DenseLayer, {'num_units': output_size, 'nonlinearity': softmax})\n",
    "        ],\n",
    "\n",
    "        max_epochs=max_epochs,\n",
    "\n",
    "        # optimization method\n",
    "        update=optimizer,\n",
    "        update_learning_rate=update_learning_rate,\n",
    "        update_momentum=update_momentum,\n",
    "\n",
    "        train_split=TrainSplit(eval_size=split_size),\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 410805 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input0      2048\n",
      "  1  dropout1    2048\n",
      "  2  dense2       200\n",
      "  3  dropout3     200\n",
      "  4  dense4         5\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m4.37742\u001b[0m      \u001b[32m10.42745\u001b[0m      0.41980      0.29470  5.22s\n",
      "      2       \u001b[36m1.54204\u001b[0m       \u001b[32m0.98658\u001b[0m      1.56302      0.29470  6.88s\n",
      "      3       \u001b[36m0.86700\u001b[0m       \u001b[32m0.84494\u001b[0m      1.02611      0.66535  4.19s\n",
      "      4       \u001b[36m0.82370\u001b[0m       \u001b[32m0.83146\u001b[0m      0.99067      0.66535  22.73s\n",
      "      5       \u001b[36m0.74942\u001b[0m       0.86624      0.86514      0.29549  21.07s\n",
      "      6       0.74951       0.86991      0.86159      0.30080  20.26s\n",
      "      7       \u001b[36m0.68605\u001b[0m       0.91036      0.75361      0.29470  19.99s\n",
      "      8       0.84186       \u001b[32m0.83128\u001b[0m      1.01272      0.66535  17.77s\n",
      "      9       0.81749       \u001b[32m0.82526\u001b[0m      0.99058      0.66535  19.37s\n",
      "     10       0.81573       \u001b[32m0.82388\u001b[0m      0.99010      0.66535  20.62s\n",
      "     11       0.81548       \u001b[32m0.82312\u001b[0m      0.99072      0.66535  18.31s\n",
      "     12       0.81538       \u001b[32m0.82258\u001b[0m      0.99126      0.66535  19.03s\n",
      "     13       0.81531       \u001b[32m0.82216\u001b[0m      0.99167      0.66535  17.84s\n",
      "     14       0.81525       \u001b[32m0.82184\u001b[0m      0.99198      0.66535  19.16s\n",
      "     15       0.82329       0.82385      0.99932      0.66535  17.29s\n",
      "     16       0.81594       \u001b[32m0.82164\u001b[0m      0.99306      0.66535  18.77s\n",
      "     17       0.81519       \u001b[32m0.82131\u001b[0m      0.99254      0.66535  18.08s\n",
      "     18       0.81511       \u001b[32m0.82118\u001b[0m      0.99260      0.66535  19.55s\n",
      "     19       0.81509       \u001b[32m0.82109\u001b[0m      0.99269      0.66535  20.75s\n",
      "     20       0.81508       \u001b[32m0.82102\u001b[0m      0.99277      0.66535  12.22s\n",
      "     21       0.81507       \u001b[32m0.82096\u001b[0m      0.99283      0.66535  10.28s\n",
      "     22       0.81507       \u001b[32m0.82092\u001b[0m      0.99287      0.66535  10.28s\n",
      "     23       0.81506       \u001b[32m0.82088\u001b[0m      0.99291      0.66535  10.26s\n",
      "     24       0.81506       \u001b[32m0.82086\u001b[0m      0.99293      0.66535  10.28s\n",
      "     25       0.81505       \u001b[32m0.82083\u001b[0m      0.99296      0.66535  10.28s\n",
      "     26       0.81505       \u001b[32m0.82082\u001b[0m      0.99297      0.66535  10.25s\n",
      "     27       0.81505       \u001b[32m0.82081\u001b[0m      0.99298      0.66535  10.27s\n",
      "     28       0.81504       \u001b[32m0.82080\u001b[0m      0.99299      0.66535  10.23s\n",
      "     29       0.81504       \u001b[32m0.82079\u001b[0m      0.99300      0.66535  10.25s\n",
      "     30       0.81504       \u001b[32m0.82078\u001b[0m      0.99301      0.66535  10.27s\n",
      "     31       0.81504       \u001b[32m0.82078\u001b[0m      0.99301      0.66535  10.29s\n",
      "     32       0.81504       \u001b[32m0.82077\u001b[0m      0.99302      0.66535  10.31s\n",
      "     33       0.81504       \u001b[32m0.82077\u001b[0m      0.99302      0.66535  10.25s\n",
      "     34       0.81504       \u001b[32m0.82077\u001b[0m      0.99302      0.66535  10.30s\n",
      "     35       0.81504       \u001b[32m0.82077\u001b[0m      0.99302      0.66535  10.24s\n",
      "     36       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.25s\n",
      "     37       0.88208       0.82373      1.07084      0.66535  10.23s\n",
      "     38       0.81611       0.82104      0.99399      0.66535  10.22s\n",
      "     39       0.81512       0.82079      0.99309      0.66535  10.21s\n",
      "     40       0.81503       0.82077      0.99301      0.66535  10.28s\n",
      "     41       0.81503       0.82077      0.99301      0.66535  10.27s\n",
      "     42       0.81504       0.82077      0.99301      0.66535  10.32s\n",
      "     43       0.81504       0.82077      0.99302      0.66535  10.27s\n",
      "     44       0.81504       0.82077      0.99302      0.66535  10.32s\n",
      "     45       0.81504       0.82077      0.99302      0.66535  10.30s\n",
      "     46       0.81504       0.82077      0.99302      0.66535  10.31s\n",
      "     47       0.81504       0.82077      0.99302      0.66535  10.28s\n",
      "     48       0.81504       0.82077      0.99302      0.66535  10.29s\n",
      "     49       0.81504       0.82076      0.99303      0.66535  10.27s\n",
      "     50       0.81504       0.82076      0.99303      0.66535  10.35s\n",
      "     51       0.81504       0.82076      0.99303      0.66535  10.28s\n",
      "     52       0.81504       0.82076      0.99303      0.66535  10.26s\n",
      "     53       0.81504       0.82076      0.99303      0.66535  10.30s\n",
      "     54       0.81504       0.82076      0.99303      0.66535  10.31s\n",
      "     55       0.81504       0.82076      0.99303      0.66535  10.29s\n",
      "     56       0.81504       0.82076      0.99303      0.66535  10.26s\n",
      "     57       0.81504       0.82076      0.99303      0.66535  10.30s\n",
      "     58       0.81504       0.82076      0.99303      0.66535  10.32s\n",
      "     59       0.81504       0.82076      0.99303      0.66535  10.28s\n",
      "     60       0.81504       0.82076      0.99303      0.66535  10.29s\n",
      "     61       0.81504       0.82076      0.99303      0.66535  10.31s\n",
      "     62       0.81504       0.82076      0.99303      0.66535  10.25s\n",
      "     63       0.81504       0.82076      0.99303      0.66535  10.30s\n",
      "     64       0.81504       0.82076      0.99303      0.66535  10.25s\n",
      "     65       0.81504       0.82076      0.99303      0.66535  10.23s\n",
      "     66       0.81504       0.82076      0.99303      0.66535  10.29s\n",
      "     67       0.81504       0.82076      0.99303      0.66535  10.28s\n",
      "     68       0.81504       0.82076      0.99303      0.66535  10.33s\n",
      "     69       0.81504       0.82076      0.99303      0.66535  10.30s\n",
      "     70       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.31s\n",
      "     71       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.29s\n",
      "     72       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.27s\n",
      "     73       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.27s\n",
      "     74       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.26s\n",
      "     75       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.28s\n",
      "     76       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.31s\n",
      "     77       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.28s\n",
      "     78       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.29s\n",
      "     79       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.30s\n",
      "     80       0.81504       \u001b[32m0.82076\u001b[0m      0.99303      0.66535  10.32s\n",
      "     81       0.81504       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.33s\n",
      "     82       0.81504       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "     83       0.81504       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.30s\n",
      "     84       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.28s\n",
      "     85       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "     86       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.25s\n",
      "     87       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.27s\n",
      "     88       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.28s\n",
      "     89       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "     90       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "     91       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.26s\n",
      "     92       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.27s\n",
      "     93       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "     94       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.31s\n",
      "     95       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.27s\n",
      "     96       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.23s\n",
      "     97       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.30s\n",
      "     98       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.24s\n",
      "     99       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.31s\n",
      "    100       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.33s\n",
      "    101       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.28s\n",
      "    102       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.26s\n",
      "    103       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.27s\n",
      "    104       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.29s\n",
      "    105       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.34s\n",
      "    106       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.49s\n",
      "    107       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.34s\n",
      "    108       0.81503       \u001b[32m0.82076\u001b[0m      0.99302      0.66535  10.34s\n",
      "    109       0.81503       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.33s\n",
      "    110       0.81503       0.82075      0.99302      0.66535  10.37s\n",
      "    111       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.36s\n",
      "    112       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.38s\n",
      "    113       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.37s\n",
      "    114       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.37s\n",
      "    115       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.32s\n",
      "    116       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.35s\n",
      "    117       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.32s\n",
      "    118       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.34s\n",
      "    119       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.41s\n",
      "    120       0.81502       \u001b[32m0.82075\u001b[0m      0.99302      0.66535  10.30s\n",
      "    121       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.30s\n",
      "    122       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.28s\n",
      "    123       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.29s\n",
      "    124       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.32s\n",
      "    125       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.33s\n",
      "    126       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.29s\n",
      "    127       0.81502       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.31s\n",
      "    128       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.27s\n",
      "    129       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.32s\n",
      "    130       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.32s\n",
      "    131       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.31s\n",
      "    132       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.30s\n",
      "    133       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.32s\n",
      "    134       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.34s\n",
      "    135       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.28s\n",
      "    136       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.30s\n",
      "    137       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.33s\n",
      "    138       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.32s\n",
      "    139       0.81501       \u001b[32m0.82075\u001b[0m      0.99301      0.66535  10.33s\n",
      "    140       0.81501       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.30s\n",
      "    141       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.26s\n",
      "    142       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.29s\n",
      "    143       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.30s\n",
      "    144       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.30s\n",
      "    145       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.29s\n",
      "    146       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.31s\n",
      "    147       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.28s\n",
      "    148       0.81500       \u001b[32m0.82074\u001b[0m      0.99301      0.66535  10.64s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x11024e490>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x11024e350>,\n",
       "     check_input=True, custom_scores=None,\n",
       "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (None, 2048)}), (<class 'lasagne.layers.noise.DropoutLayer'>, {'p': 0.2}), (<class 'lasagne.layers.dense.DenseLayer'>, {'num_units': 200, 'nonlinearity': <function rectify at 0x10c95ff50>}), (<class 'lasagne.layers.noise.DropoutLayer'>, {'p': 0.5}), (<class 'lasagne.layers.dense.DenseLayer'>, {'num_units': 5, 'nonlinearity': <function softmax at 0x10c95fb90>})],\n",
       "     loss=None, max_epochs=500, more_params={},\n",
       "     objective=<function objective at 0x11024bc80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10cb0f2a8>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x112811098>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x112aeb8c0>],\n",
       "     regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x112ecca50>,\n",
       "     update=<function adam at 0x10cb0fd70>, update_learning_rate=0.01,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne.visualize import draw_to_notebook\n",
    "from nolearn.lasagne.visualize import plot_loss\n",
    "from nolearn.lasagne.visualize import plot_conv_weights\n",
    "from nolearn.lasagne.visualize import plot_conv_activity\n",
    "from nolearn.lasagne.visualize import plot_occlusion\n",
    "from nolearn.lasagne.visualize import plot_saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LasagneNeuralNetwork():\n",
    "    def __init__(self, ):\n",
    "        self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
